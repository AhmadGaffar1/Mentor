"""
======================================================
FIND VIDEOs METADATA USING ( YOUTUBE API: all metadata) , ( ASSEMPLYAI: transcript )
======================================================
"""

# ================================================================
# IMPORT REQUIRED MODULES
# ================================================================

from __future__ import annotations
import os
import re
import time
import json
import random
import logging
from pathlib import Path
from uuid import UUID
from functools import lru_cache

import requests
from pytube import YouTube, exceptions as pytube_exceptions
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from urllib.error import HTTPError, URLError
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound
from APP.Configration import YOUTUBE_API_KEY, ASSEMBLYAI_API_KEY, MAX_TIME_FOR_TRANSCRIPT_EXTRACTION

# ------------------------------------------------
# DEFINE REQUIRED CREDENTIALS
# ------------------------------------------------

youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)

# ------------------------------------------------
# LOGGING SETUP
# ------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.FileHandler("youtube_processing.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

# ================================================================
# META DATA CLEAN DECLARATION FOR DEEP INTUITION
# ================================================================

# -------------------------------------------------------------------
# DEFAULT_META
# -------------------------------------------------------------------
# Represents the unified metadata schema for any processed YouTube video.
# This structure ensures consistent keys regardless of whether data comes
# from the YouTube Data API or AssemblyAI transcription.
#
# - `video_id` is mandatory and used to fetch all other metadata fields.
# - All other fields are optional and may remain None if unavailable.
#
# Field definitions:
# -------------------------------------------------------------------
DEFAULT_META: dict[str, object] = {
    # Basic metadata (fetched via YouTube Data API)
    "video_id": None,       # Unique YouTube video identifier (always required)
    "title": None,          # Video title
    "link": None,           # Video link
    "description": None,    # Description that existed under YouTube Video that known by (Description Box)
    "channel": None,        # Channel or author name
    "duration": None,       # ISO 8601 duration string (e.g., "PT10M15S")
    "has_captions": None,   # Boolean indicating if YouTube captions exist

    # (Captions Text: Provided by YouTube Captions API) or (Transcript Text: Transcribed by AssemblyAI API as external tool)
    "text": None,

    # Transcript source
    # Specifies which system generated `text`:
    #   - "YouTube Captions" → fetched via YouTube Captions API
    #   - "AssemblyAI"       → generated by AssemblyAI speech-to-text
    "transcript_source": None,

    # Extended data (populated only if AssemblyAI was used)
    "summary": None,        # AI-generated summary of the transcript
    "chapters": [],         # List of chapters with start/end times + headlines
}
# -------------------------------------------------------------------

# ================================================================
# HELPER FUNCTIONS
# ================================================================

def transcribe_with_assemblyai(file_path: str) -> dict:
    """
    Transcribes an audio file using AssemblyAI and returns the transcript,
    summary, and chapters if available.

    Args:
        file_path (str): Path to the local audio file (.mp4, .mp3, etc.)

    Returns:
        dict: {
            "text": str,
            "summary": str,
            "chapters": list,
        }
    """
    headers = {"authorization": ASSEMBLYAI_API_KEY}
    start_time = time.time()

    # ---- Step 1: Upload file ----
    try:
        with open(file_path, "rb") as f:
            upload_response = requests.post(
                "https://api.assemblyai.com/v2/upload",
                headers=headers,
                data=f,
                timeout=60,
            )
        upload_response.raise_for_status()
        audio_url = upload_response.json()["upload_url"]
        logging.info(f"[AssemblyAI] File uploaded: {file_path}")
    except Exception as e:
        logging.error(f"[AssemblyAI Upload Error] {e}")
        return {"text": "", "summary": None, "chapters": []}

    # ---- Step 2: Request transcription ----
    payload = {
        "audio_url": audio_url,
        "speaker_labels": True,
        "auto_chapters": True,
        "summary_model": "informative",
    }

    try:
        transcript_response = requests.post(
            "https://api.assemblyai.com/v2/transcript",
            json=payload,
            headers=headers,
            timeout=60,
        )
        transcript_response.raise_for_status()
        transcript_id = transcript_response.json()["id"]
        logging.info(f"[AssemblyAI] Transcription started (ID: {transcript_id})")
    except Exception as e:
        logging.error(f"[AssemblyAI Request Error] {e}")
        return {"text": "", "summary": None, "chapters": []}

    # ---- Step 3: Poll until complete ----
    while True:
        try:
            poll = requests.get(
                f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
                headers=headers,
                timeout=30,
            )
            poll.raise_for_status()
            data = poll.json()
        except Exception as e:
            logging.warning(f"[AssemblyAI Polling Error] {e}")
            time.sleep(5)
            continue

        if data["status"] == "completed":
            elapsed = time.time() - start_time
            logging.info(f"[AssemblyAI] Done in {elapsed:.2f}s")

            # ---- Step 4: Optional cleanup ----
            try:
                requests.delete(
                    f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
                    headers=headers,
                    timeout=10,
                )
            except Exception:
                logging.debug(f"[AssemblyAI] Cleanup skipped for {transcript_id}")

            return {
                "text": data.get("text", ""),
                "summary": data.get("summary", ""),
                "chapters": data.get("chapters", []),
            }

        elif data["status"] == "error":
            logging.error(f"[AssemblyAI Error] {data.get('error')}")
            return {"text": "", "summary": None, "chapters": []}

        if time.time() - start_time > MAX_TIME_FOR_TRANSCRIPT_EXTRACTION:
            logging.error("[AssemblyAI Timeout] Transcription took too long")
            return {"text": "", "summary": None, "chapters": []}

        time.sleep(5)



def fetch_transcript(video_id: str, max_retries: int = 5):
    """
    Fetches transcript for a YouTube video safely with retry/backoff handling.
    Handles 429 (Too Many Requests) gracefully with exponential backoff.
    """
    attempt = 0

    while attempt < max_retries:
        try:
            transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])
            logging.info(f"[Captions] Transcript retrieved for {video_id}")
            return transcript

        except TranscriptsDisabled:
            logging.warning(f"[Captions] Transcripts disabled for {video_id}")
            return None

        except NoTranscriptFound:
            logging.warning(f"[Captions] No transcript found for {video_id}")
            return None

        except Exception as e:
            err_msg = str(e)

            # Handle rate limiting
            if "429" in err_msg or "Too Many Requests" in err_msg:
                wait_time = 10 * (2 ** attempt) + random.uniform(0, 5)
                logging.warning(f"[429] Rate limited. Backing off for {wait_time:.1f}s (attempt {attempt+1}/{max_retries})")
                time.sleep(wait_time)
                attempt += 1
                continue

            # Any other unexpected error
            logging.error(f"[Captions] Unexpected error fetching captions for {video_id}: {err_msg}")
            return None

    logging.error(f"[Captions] Giving up on {video_id} after {max_retries} retries (still rate-limited)")
    return None

# Optional: define custom error types for clarity
class YouTubeDownloadError(Exception):
    """Raised when audio download from YouTube fails."""
    pass

def is_valid_youtube_id(video_id: str) -> bool:
    """Simple check for a valid YouTube video ID (11 allowed chars)."""
    return bool(re.fullmatch(r"[A-Za-z0-9_-]{11}", video_id))

def download_audio(video_id: str, output_dir: str = ".", retries: int = 2, delay: int = 5) -> str:
    """
    Download the audio track of a YouTube video using pytube.

    Args:
        video_id (str): YouTube video ID (11 characters).
        output_dir (str): Directory to save the .mp3 file.
        retries (int): Number of retry attempts on transient errors.
        delay (int): Seconds to wait between retries.

    Returns:
        str: Full path to the downloaded audio file.

    Raises:
        YouTubeDownloadError: If the video cannot be downloaded or ID is invalid.
    """
    if not is_valid_youtube_id(video_id):
        raise YouTubeDownloadError(f"Invalid YouTube video ID: {video_id}")

    url = f"https://www.youtube.com/watch?v={video_id}"
    filename = f"{video_id}.mp3"
    output_path = os.path.join(output_dir, filename)

    attempt = 0
    while attempt <= retries:
        try:
            logging.info(f"[YouTube] Attempting download for {video_id} (try {attempt + 1})")

            yt = YouTube(url)
            audio_stream = yt.streams.filter(only_audio=True).first()
            if not audio_stream:
                raise YouTubeDownloadError(f"No audio stream found for {video_id}")

            # Download and rename to .mp3
            out_file = audio_stream.download(output_path=output_dir, filename=filename)
            logging.info(f"[YouTube] Audio downloaded successfully for {video_id}")
            return out_file

        except (HTTPError, URLError) as net_err:
            logging.warning(f"[YouTube] Network error for {video_id}: {net_err}")
            if attempt < retries:
                attempt += 1
                time.sleep(delay)
                continue
            raise YouTubeDownloadError(f"Network error after {retries + 1} attempts: {net_err}") from net_err

        except pytube_exceptions.RegexMatchError:
            raise YouTubeDownloadError(f"Invalid YouTube URL or video ID: {url}")

        except pytube_exceptions.VideoUnavailable:
            raise YouTubeDownloadError(f"Video unavailable or restricted: {video_id}")

        except HTTPError as http_err:
            # 400 = invalid request (often wrong ID or blocked)
            if hasattr(http_err, 'code') and http_err.code == 400:
                raise YouTubeDownloadError(f"HTTP 400: Invalid or non-existent video ID ({video_id})")
            raise YouTubeDownloadError(f"YouTube HTTP error for {video_id}: {http_err}") from http_err

        except Exception as e:
            logging.error(f"[YouTube Download Error] {video_id}: {e}")
            raise YouTubeDownloadError(f"Unexpected error for {video_id}: {e}") from e

        finally:
            attempt += 1

    # If we exit loop without returning
    raise YouTubeDownloadError(f"Failed to download audio for {video_id} after {retries + 1} attempts.")



# Cache works automatically — but only if:
#   - The function is pure (no side effects, depends only on inputs).
#   - Arguments are hashable (e.g., strings, numbers, tuples — not lists or dicts).
# If you ever want to clear the cache:
#   - get_video_info.cache_clear()
# Or check the stats of cache:
#   - print(get_video_info.cache_info())
# Example for cache status:
#   - CacheInfo(hits=5, misses=2, maxsize=100, currsize=2)
# Use cache only by below line:
@lru_cache(maxsize=100)
def get_video_info(video_id: str, url: str) -> dict | None:
    try:
        response = youtube.videos().list(
            part="snippet,contentDetails",
            id=video_id
        ).execute()

        items = response.get("items", [])
        if not items:
            return None

        video = items[0]
        snippet = video["snippet"]
        info = {
            "video_id": video_id,
            "title": snippet.get("title"),
            "link": url,
            "description": snippet.get("description"),
            "channel": snippet.get("channelTitle"),
            "duration": video["contentDetails"].get("duration"),
            "has_captions": False,
        }

        captions_response = youtube.captions().list(
            part="snippet", videoId=video_id
        ).execute()

        info["has_captions"] = len(captions_response.get("items", [])) > 0
        return info

    except HttpError as e:
        logging.error(f"[YouTube API HTTP Error] {e}")
        return None
    except Exception as e:
        logging.error(f"[YouTube Error] Failed to get metadata for {video_id}: {e}")
        return None

def fetch_youtube_captions(video_id: str, prefer_langs: list[str] = ["en"]) -> str | None:
    """
    Robustly fetch captions/transcript for a video_id.

    Strategy:
      1. list_transcripts(video_id) and try to fetch a manually created transcript in preferred languages
      2. fall back to generated transcript in preferred languages
      3. fall back to any transcript whose language startswith a preferred language
      4. try translating available transcript to 'en' if available
      5. return None with detailed logs if nothing works

    Returns combined transcript text or None.
    """
    try:
        logging.debug(f"[Captions] list_transcripts -> video_id={video_id}")
        transcripts = YouTubeTranscriptApi.list_transcripts(video_id)

        # 1) Try manually created transcripts first
        for lang in prefer_langs:
            try:
                logging.debug(f"[Captions] trying manual transcript for lang={lang}")
                transcript = transcripts.find_manually_created_transcript([lang])
                logging.debug(f"[Captions] found manual transcript: {getattr(transcript, 'language_code', 'unknown')}")
                tlist = transcript.fetch()
                text = " ".join([t["text"] for t in tlist])
                return text
            except NoTranscriptFound:
                logging.debug(f"[Captions] no manual transcript for lang={lang}")

        # 2) Try generated transcripts for preferred languages
        for lang in prefer_langs:
            try:
                logging.debug(f"[Captions] trying generated transcript for lang={lang}")
                transcript = transcripts.find_generated_transcript([lang])
                logging.debug(f"[Captions] found generated transcript: {getattr(transcript, 'language_code', 'unknown')}")
                tlist = transcript.fetch()
                text = " ".join([t["text"] for t in tlist])
                return text
            except NoTranscriptFound:
                logging.debug(f"[Captions] no generated transcript for lang={lang}")

        # 3) Fallback: iterate all transcripts and pick first that startswith preferred language
        logging.debug("[Captions] trying any available transcript with language match")
        for t in transcripts:
            lc = getattr(t, "language_code", "")
            if any(lc.startswith(pl) for pl in prefer_langs):
                try:
                    logging.debug(f"[Captions] attempting fetch for transcript {lc}")
                    tlist = t.fetch()
                    text = " ".join([x["text"] for x in tlist])
                    return text
                except Exception as e:
                    logging.debug(f"[Captions] fetch failed for {lc}: {e}")

        # 4) Try translate any transcript to preferred language (if supported)
        logging.debug("[Captions] attempting translation fallback")
        for t in transcripts:
            try:
                # some transcript objects support .translate(lang)
                translated = t.translate(prefer_langs[0])
                tlist = translated.fetch()
                text = " ".join([x["text"] for x in tlist])
                logging.debug(f"[Captions] used translation from {getattr(t, 'language_code', 'unknown')}")
                return text
            except Exception as e:
                logging.debug(f"[Captions] translation not available for {getattr(t, 'language_code', 'unknown')}: {e}")

        # nothing found
        logging.warning(f"[Captions] No captions available in preferred languages for {video_id}")
        return None

    except TranscriptsDisabled:
        logging.warning(f"[Captions] Transcripts disabled by uploader for video {video_id}")
        return None
    except NoTranscriptFound:
        logging.warning(f"[Captions] No transcripts found for {video_id}")
        return None
    except Exception as e:
        logging.error(f"[Captions] Unexpected error fetching captions for {video_id}: {e}")
        return None

def extract_video_id(url: str) -> str | None:
    patterns = [
        r"(?:v=|youtu\.be/)([a-zA-Z0-9_-]{11})",
        r"youtube\.com/embed/([a-zA-Z0-9_-]{11})"
    ]
    for p in patterns:
        match = re.search(p, url)
        if match:
            return match.group(1)
    return None

# ================================================================
# MAIN FUNCTION
# ================================================================

def process_videos(id: UUID, url: str) -> dict[str, object]:
    """
    Process a list of YouTube video URLs by:
      1. Extracting metadata via YouTube Data API.
      2. Fetching captions if available.
      3. Falling back to AssemblyAI transcription if captions are missing.

    Args:
        video_urls (list[str]): List of YouTube video URLs.

    Returns:
        list[dict]: Structured list containing video metadata + transcripts.
    """

    start_time = time.time()
    result: dict[str,object] = dict(DEFAULT_META)

    # ---------------------------------------------
    # Step[01]: Extract video ID from the YouTube URL
    # ---------------------------------------------
    video_id = extract_video_id(url)
    if not video_id:
        logging.error(f"Invalid YouTube URL: {url}")
        result["link"] = url
        result["error"] = "YouTube Error 400: Invalid or non-existent video ID"
        return result
    # ---------------------------------------------
    # Step[02]: Retrieve metadata (safe fallback to defaults)
    # ---------------------------------------------
    result.update(get_video_info(video_id,url) or dict(DEFAULT_META))
    logging.info(f"\nProcessing video: {result.get('title') or video_id}")

    try:
        # ---------------------------------------------
        # Step[03]: captions exist → fetch them
        # ---------------------------------------------
        if result.get("has_captions") and False:
            captions_text = fetch_youtube_captions(video_id)
            if captions_text:
                result["text"] = captions_text
                result["transcript_source"] = "YouTube Captions"
            result["summary"] = None
            result["chapters"] = []
            logging.info(f"Captions retrieved for {video_id}")
        # ---------------------------------------------
        # Step[04]: Otherwise → download audio & transcribe
        # ---------------------------------------------
        else:
            print ("\n\nAhmad Now I will use Assembly AI API for transcribing !!!")

            try:
                audio_path = download_audio("jGwO_UgTS7I", output_dir="downloads")
                print("Audio saved at:", audio_path)
            except YouTubeDownloadError as e:
                logging.error(f"Audio extraction failed: {e}")

            try:
                print("Ahmad Abdulmaaboud Now I will use Assembly AI API for transcribing !!!")
                # time.sleep(random.uniform(5, 12)) # Global rate limit between each video
                transcription_result = fetch_transcript(video_id)
                time.sleep(60)
                print("Ahmad Abdulmaaboud Suliman Now I will use Assembly AI API for transcribing !!!")
                if transcription_result.get("text"):
                    result.update(transcription_result)
                    print("Ahmad Abdulmaaboud Suliman Gaffar Now I will use Assembly AI API for transcribing !!!\n\n")
                    result["transcript_source"] = "AssemblyAI"
                logging.info(f"Transcription completed for {video_id}")
            finally:
                if os.path.exists(file_path):
                    os.remove(file_path)

    except Exception as e:
        result.update({
            "text": "",
            "summary": None,
            "chapters": [],
            "error": str(e),
        })
        logging.error(f"error failed for {video_id}: {e}")

    # ---------------------------------------------
    # Step[05]: Add finalized metadata to results
    # ---------------------------------------------
    elapsed = time.time() - start_time
    logging.info(f"Finished processing {video_id} in {elapsed:.2f} seconds")  # ✅ performance info

    # ---------------------------------------------
    # Step[06]: Return structured results list
    # ---------------------------------------------
    return result